import glob
import re
import os
import pandas as pd

# Set the prefix to activate the conda environment
shell.prefix("source $(conda info --base)/etc/profile.d/conda.sh && conda activate fastq_frip_env && ")

###############
# Input
###############
chip_fastqs_path = config["input"]["ChIP_fastqs"]
if config["input"]["ChIP_input_table"] != '':
    chip_input_table = pd.read_table(config["input"]["ChIP_input_table"])

###############
# Parameters
###############
index = config["input"]["bowtie_index"]
process = config["common_params"]["processes"]
include_spikein = config["common_params"]["include_spikein"]
index_primary = config["spikein_params"]["index_primary"]
index_spikein = config["spikein_params"]["index_spikein"]
binsize = config["bamcoverage_params"]["binsize"]

quality = config["samtools_params"]["quality"]
distance = config["samtools_params"]["distance"]

if config["macs2_params"]["broad"]:
    broad_peaks_option = "--broad"
else:
    broad_peaks_option = ""

###############
# Output path
###############
chip_result_folder = config["output"]["ChIP_output_path"]

# Check if the directory exist. If not, create the directory
if not os.path.exists(chip_result_folder):
    os.makedirs(chip_result_folder)

########################
# Input validation
########################
if include_spikein:
    if index_spikein == "" or index_spikein == None:
        raise ValueError("if you include spikein procedure, then index_spikein need to be spcified")

if index_spikein != "" and index_spikein != None:
    if not include_spikein:
        raise ValueError("Since index_spikein is spcified, <include_spikein> parameter should be set to true")

########################
# Helper functions
########################
def get_chipseq_input_path(wildcards):
    input_sample_name = chip_input_table[chip_input_table.ChIP == wildcards.sample_name]['Input'].iloc[0]  
    input_file = f"{wildcards.pathway_to_folder}/{input_sample_name}/{input_sample_name}.q{quality}.{wildcards.type}.bam" 
    
    return input_file

def get_chipseq_input_spikestats_path(wildcards):
    input_sample_name = chip_input_table[chip_input_table.ChIP == wildcards.sample_name]['Input'].iloc[0]  
    input_spikeinstats_file = f"{wildcards.pathway_to_folder}/{input_sample_name}/{input_sample_name}.spikein.stats"  
    
    return input_spikeinstats_file

def get_fastq_paths(wildcards):
    plain = f"{chip_fastqs_path}/{wildcards.sample_name}.fastq"
    gzipped = f"{chip_fastqs_path}/{wildcards.sample_name}.fastq.gz"
    paired1 = f"{chip_fastqs_path}/{wildcards.sample_name}_1.fastq"
    paired2 = f"{chip_fastqs_path}/{wildcards.sample_name}_2.fastq"

    if os.path.exists(plain):
        return plain
    elif os.path.exists(gzipped):
        return gzipped
    elif os.path.exists(paired2):
        return [paired1, paired2]

    raise FileNotFoundError(f"No input file found for sample {wildcards.sample_name}, here's the path{gzipped}, {wildcards.sample_name}")

def is_paired_end(sample_name):
    paired1 = f"{chip_fastqs_path}/{sample_name}_1.fastq"
    paired2 = f"{chip_fastqs_path}/{sample_name}_2.fastq"

    if os.path.exists(paired1) and os.path.exists(paired2):
        return True
    
    return False

#############################################
# Create lists of output filenames
#############################################
# q: would this be more readable in an if/else statement for paired/single end?
sample_filenames = glob.glob(chip_fastqs_path+'/*.fastq*')
fastq_filename_pattern = r"(_[12])?\.fastq.*"
samples = [re.sub(fastq_filename_pattern, '', s.split('/')[-1]) for s in sample_filenames]
samples = list(set(samples))
se_samples = [s for s in samples if not is_paired_end(s)]
pe_samples = [s for s in samples if is_paired_end(s)]

sam = expand(
        f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.sam",
        sample_name=samples
    )

bam_se = expand(
        f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.q{quality}.bam",
        sample_name=se_samples
    )
bam_pe = expand(
        f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.pairedend.q{quality}.bam",
        sample_name=pe_samples
    )

fixed_bam = expand(
        f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.q{quality}.bam",
        sample_name=pe_samples
    )

sort_bam = expand(
        f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.q{quality}.sort.bam",
        sample_name=samples
    )

dedup_bam = expand(
        f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.q{quality}.dedup.bam",
        sample_name=samples
    )

if include_spikein:
    spikein_stats_files = expand(
            f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.spikein.stats",
            sample_name=samples
        )

    primary_sort_bam = expand(
            f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.q{quality}.{index_primary}.sort.bam",
            sample_name=samples
        )

    spikein_sort_bam = expand(
            f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.q{quality}.{index_spikein}.sort.bam",
            sample_name=samples
        )
    if config["input"]["ChIP_input_table"] == '' :
        bw = expand(
            f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.{index_primary}.bw",
            sample_name=samples
        )
        bw_with_input = []

        peaks_bed = expand(
            f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.q{quality}.{index_primary}.sort_peaks.narrowPeak",
            sample_name=samples
        )
        peaks_bed_with_input = []

    else:
        have_input = [s for s in samples if s in chip_input_table['ChIP'].unique()]
        no_input = [s for s in samples if s not in chip_input_table['ChIP'].unique()]
        bw = expand(
                f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.{index_primary}.rescale.bw",
                sample_name=have_input
            )
        bw_with_input = expand(
                f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.{index_primary}.bw",
                sample_name=no_input
            )
        peaks_bed = expand(
                f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.q{quality}.{index_primary}.sort_peaks.narrowPeak",
                sample_name=no_input
            )
        peaks_bed_with_input = expand(
                f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.q{quality}.{index_primary}.sort.withinput_peaks.narrowPeak",
                sample_name=have_input
            )
else:
    spikein_stats_files = []
    primary_sort_bam = []
    spikein_sort_bam = []
    bw_with_input = []
    index_primary = "no_primary"
    index_spikein = "no_spikein"
    bw = expand(
            f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.bw",
            sample_name=samples
        )
    if config["input"]["ChIP_input_table"] == '' :
        peaks_bed = expand(
            f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.q{quality}.dedup_peaks.narrowPeak",
            sample_name=samples
        )
        peaks_bed_with_input = []

    else:
        have_input = [s for s in samples if s in chip_input_table['ChIP'].unique()]
        no_input = [s for s in samples if s not in chip_input_table['ChIP'].unique()]
        peaks_bed = expand(
                f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.q{quality}.dedup_peaks.narrowPeak",
                sample_name=no_input
            )
        peaks_bed_with_input = expand(
                f"{chip_result_folder}/{{sample_name}}/{{sample_name}}.q{quality}.dedup.withinput_peaks.narrowPeak",
                sample_name=have_input
            )

rule all:
    input:
        sam,
        bam_se,
        bam_pe,
        fixed_bam,
        sort_bam,
        dedup_bam,
        spikein_stats_files,
        primary_sort_bam,
        spikein_sort_bam,
        bw,
        bw_with_input,
        peaks_bed,
        peaks_bed_with_input,

##############################
# Alignment starts here
##############################
# automatic trim and alignment
rule bowtie2_map:
    input:
        files = get_fastq_paths
    params:
        trimmed_fastq_path1 = f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.trimmed.fastq",
        trimmed_fastq_path2 = f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}_2.trimmed.fastq"
    wildcard_constraints:
        sample_name = "[a-zA-Z0-9_-]+"
    threads: process
    output:
        temp(f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.sam")
    shell:
        """
        files=({input.files})
        num_files=${{#files[@]}}

        if [ "$num_files" -eq 1 ]; then
            fastp --thread {process} -i {input.files} -o {params.trimmed_fastq_path1}
            bowtie2 -p {process} -x {index} -U {params.trimmed_fastq_path1} -S {output}
            rm {params.trimmed_fastq_path1}
        elif [ "$num_files" -eq 2 ]; then
            fastp --thread {process} -i {input.files[0]} -I {input.files[1]} -o {params.trimmed_fastq_path1} -O {params.trimmed_fastq_path2}
            bowtie2 -p {process} -x {index} -1 {params.trimmed_fastq_path1} -2 {params.trimmed_fastq_path2}  -S {output}
            rm {params.trimmed_fastq_path1} {params.trimmed_fastq_path2}
        fi
        """

# skip alignments with MAPQ smaller than INT {quality} and type of reads include in argument -F 1804, which includes read unmapped, mate unmapped, not primary alignment, Read fails platform/vendor quality checks, Read is PCR or optical duplicate
rule samtools_filter:
    input:
        f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.sam"
    wildcard_constraints:
        sample_name="[^.]+"
    threads: process
    output:
        temp(f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}{{end_type}}.q{quality}.bam")
    shell:
        "samtools view -F 1804 --threads {process} -h -q {quality} {input} > {output}"

# This is for paired-end fastq file only. Sort by reads name and then correctly remove secondary and unmapped reads
rule samtools_fixmate:
    input:
        f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.pairedend.q{quality}.bam"
    params:
        sorted_name = f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.sorted.bam"
    wildcard_constraints:
        sample_name="[^.]+"
    threads: process
    output:
        temp(f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.bam")
    shell:
        """
        samtools sort -n -@{process} {input} -o {params.sorted_name}
        samtools fixmate -m -r {params.sorted_name} {output}
        rm {params.sorted_name}
        """

# back to sorting by genomic coordinates for markdup
rule samtools_sort:
    input:
        f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.bam"
    wildcard_constraints:
        sample_name="[^.]+"
    threads: process
    output:
        temp(f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.sort.bam")
    shell:
        """
        samtools sort -@{process} {input} -o {output}
        samtools index --threads {process} {output}
        """

# remove duplicate reads
rule samtools_markdup:
    input:
        f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.sort.bam"
    params:
        stats_file_path = f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.markdup.stats"
    wildcard_constraints:
        sample_name="[^.]+"
    threads: process
    output:
        bam = f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.dedup.bam"
    shell:
        """
        samtools markdup -f {params.stats_file_path} -r -d {distance} {input} {output.bam}
        samtools index --threads {process} {output.bam}
        """

############################################################
#  Spike-in ChIP protocol
############################################################
# Count the number of reads that map to each genome and print the ratio
rule spikein_stats:
    input:
        f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.dedup.bam"
    output:
        f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.spikein.stats"
    shell:
        """
        primary_reads=$(samtools idxstats {input} | grep -E '^{index_primary}_' | \
                            grep -v -E '(_random|_alt|_fix|_decoy|chrM|chrY|chrUn)' | \
                                awk '{{sum += $3}} END {{print sum}}')
        spikein_reads=$(samtools idxstats {input} | grep -E '^{index_spikein}_' | \
                            grep -v -E '(_random|_alt|_fix|_decoy|chrM|chrY|chrUn)' | \
                                awk '{{sum += $3}} END {{print sum}}')
        echo -e "{index_primary}_reads=$primary_reads" >> {output} 
        echo "{index_spikein}_reads=$spikein_reads" >> {output} 
        echo "ratio of {index_primary} to {index_spikein} reads is" >> {output} 
        echo "scale=2; $primary_reads/$spikein_reads" | bc >> {output} 
        """

# Use grep to create a bam file with only one species reads
rule separate_reads:
    input:
        f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.dedup.bam"
    params:
        primary_bam_tmp1 = f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.{index_primary}1.bam",
        primary_bam_tmp2 = f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.{index_primary}2.bam",
        primary_header_tmp = f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.{index_primary}.newHeader.txt",
        spikein_bam_tmp1 = f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.{index_spikein}1.bam",
        spikein_bam_tmp2 = f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.{index_spikein}2.bam",
        spikein_header_tmp = f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.{index_spikein}.newHeader.txt",
        
    threads: process
    output:
        output1 = f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.{index_primary}.sort.bam",
        output2 = f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.{index_spikein}.sort.bam"
    shell:
        """
        samtools view -h {input} | grep '.*{index_primary}.*' | samtools view -b -> {params.primary_bam_tmp1}
        samtools view -H {params.primary_bam_tmp1} | sed 's/{index_primary}_chr/chr/' > {params.primary_header_tmp}
        samtools reheader {params.primary_header_tmp} {params.primary_bam_tmp1} > {params.primary_bam_tmp2}
        samtools sort {params.primary_bam_tmp2} -o {output.output1}
        samtools index --threads {process} {output.output1}
        rm {params.primary_bam_tmp1} {params.primary_bam_tmp2} {params.primary_header_tmp}

        samtools view -h {input} | grep '.*{index_spikein}.*' | samtools view -b -> {params.spikein_bam_tmp1}
        samtools view -H {params.spikein_bam_tmp1} | sed 's/{index_spikein}_chr/chr/' > {params.spikein_header_tmp}
        samtools reheader {params.spikein_header_tmp} {params.spikein_bam_tmp1} > {params.spikein_bam_tmp2}
        samtools sort {params.spikein_bam_tmp2} -o {output.output2}
        samtools index --threads {process} {output.output2}
        rm {params.spikein_bam_tmp1} {params.spikein_bam_tmp2} {params.spikein_header_tmp}
        """

############################################################
#  Create bigwig file
############################################################
# create an unscaled bigwig file
rule bw:
    input:
        f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.dedup.bam"
    wildcard_constraints:
        sample_name="[^.]+"
    output:
        f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.bw"
    shell:
        "bamCoverage -b {input} -o {output} -of bigwig --binSize {binsize}"

# create an unscaled bigwig file for spike-in
rule spikein_bw:
    input:
        f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.{index_primary}.sort.bam"
    wildcard_constraints:
        sample_name="[^.]+"
    output:
        f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.{index_primary}.bw"
    shell:
        "bamCoverage -b {input} -o {output} -of bigwig --binSize {binsize}"

# Spike-in Normalization
rule rescaling:
    input:
        chip_stats = f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.spikein.stats",
        chip_input_stats = lambda wildcards: get_chipseq_input_spikestats_path(wildcards),
        chip_bam = f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.{index_primary}.sort.bam"
    output:
        f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.{index_primary}.rescale.bw"
    shell:
        """
        primary_reads=$(awk -F'=' '/{index_primary}_reads/{{print $2}}' {input.chip_stats}) 
        spikein_reads=$(awk -F'=' '/{index_spikein}_reads/{{print $2}}' {input.chip_stats}) 
        chip_input_primary_reads=$(awk -F'=' '/{index_primary}_reads/{{print $2}}' {input.chip_input_stats})  
        chip_input_spikein_reads=$(awk -F'=' '/{index_spikein}_reads/{{print $2}}' {input.chip_input_stats})
        factor=`echo "scale=20; $chip_input_spikein_reads / $chip_input_primary_reads / $spikein_reads * 15000000" | bc`
        echo "Scaling_factor=$factor" >> {input.chip_stats}
        bamCoverage -b {input.chip_bam} -o {output} -of bigwig --binSize {binsize} --scaleFactor $factor
        """

##############################
# Calling peaks
##############################
rule bam_to_bed:
    input:
        f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.{{type}}.bam"
    params:
        output_prefix = f"{{sample_name}}.q{quality}.{{type}}", 
        output_dir = f"{{pathway_to_folder}}/{{sample_name}}/",
        fastq_files = lambda wildcards: get_fastq_paths(wildcards) # q: can this be done as get_fastq_paths(wildcards, chip_fastqs_input)?
    output:
        f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.{{type}}_peaks.narrowPeak"
    shell:
        """
        files=({params.fastq_files})
        num_files=${{#files[@]}}

        if [ "$num_files" -eq 1 ]; then
            macs2 callpeak {broad_peaks_option} -t {input} -n {params.output_prefix} --outdir {params.output_dir}
        elif [ "$num_files" -eq 2 ]; then
            macs2 callpeak {broad_peaks_option} -f BAMPE -t {input} -n {params.output_prefix} --outdir {params.output_dir}
        fi
        """

rule bam_to_bed_wi:
    input:
        bam = f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.{{type}}.bam",
        chip_input_file = lambda wildcards: get_chipseq_input_path(wildcards),
    params:
        output_prefix = f"{{sample_name}}.q{quality}.{{type}}.withinput", 
        output_dir = f"{{pathway_to_folder}}/{{sample_name}}/",
        fastq_files = lambda wildcards: get_fastq_paths(wildcards)
    output:
        f"{{pathway_to_folder}}/{{sample_name}}/{{sample_name}}.q{quality}.{{type}}.withinput_peaks.narrowPeak"
    shell:
        """
        files=({params.fastq_files})
        num_files=${{#files[@]}}

        if [ "$num_files" -eq 1 ]; then
            macs2 callpeak {broad_peaks_option} -t {input.bam} -c {input.chip_input_file} -n {params.output_prefix} --outdir {params.output_dir}
        elif [ "$num_files" -eq 2 ]; then
            macs2 callpeak {broad_peaks_option} -f BAMPE -t {input.bam} -c {input.chip_input_file} -n {params.output_prefix} --outdir {params.output_dir}
        fi
        """